{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Setting up some basic packages for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in training and testing data. Mapping salary to binary value (this is what we want to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "df = pd.read_csv(\"adult-data.csv\")\n",
    "train, test = train_test_split(df, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "train['income'] = train['income'].map({\"<=50K\":0, \">50K\":1})\n",
    "test['income'] = test['income'].map({\"<=50K\":0, \">50K\":1})\n",
    "# To binary mapping\n",
    "train['race'] = train['race'].map({\"Black\": 0, \"Other\": 1, \"Amer-Indian-Eskimo\": 1, \"Asian-Pac-Islander\": 1, \"White\":1})\n",
    "test['race'] = test['race'].map({\"Black\": 0, \"Other\": 1, \"Amer-Indian-Eskimo\": 1, \"Asian-Pac-Islander\": 1, \"White\":1})\n",
    "\n",
    "Y = train['income']\n",
    "Y_race = train['race']\n",
    "X = train.drop(['income', 'fnlwgt', 'native.country', 'race'], axis = 1)\n",
    "Y_test = test['income']\n",
    "Y_test_race = test['race']\n",
    "X_test = test.drop(['income', 'fnlwgt', 'native.country', 'race'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive oversampling of our training data. This one of the mechanisms we will test to see its effect on bias. We simply oversample the minority class (black in this case) so that our classes are more balanced. We are going to resample based on some coefficient RESAMPLE_COEFFICIENT. If this is 1, we simple resample the total amount in the minority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499 26048\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "minority = train[train['race']== 0]\n",
    "print(len(minority), len(train))\n",
    "RESAMPLE_COEFFICIENT = 1.5\n",
    "oversample = minority.sample(int(RESAMPLE_COEFFICIENT * len(minority)), replace = True, random_state = 1)\n",
    "train_o = pd.concat([train, oversample], axis = 0)\n",
    "##Perform similar X, Y split on train_o, the oversampled training data\n",
    "Y_o_race = train_o['race']\n",
    "Y_o = train_o['income']\n",
    "X_o = train_o.drop(['income', 'fnlwgt', 'native.country', 'race'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic analysis of race groups above and below 50 K (\"rich\" and \"poor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = train.groupby('race').size().reset_index()\n",
    "\n",
    "rich = train[train['income'] == 1]\n",
    "rich = rich.groupby('race').size().reset_index()\n",
    "rich[0] = rich[0]/total[0]\n",
    "\n",
    "poor = train[train['income'] == 0]\n",
    "poor = poor.groupby('race').size().reset_index()\n",
    "poor[0] = poor[0]/total[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "fig.set_size_inches(10,3)\n",
    "ax1.bar(rich['race'], rich[0])\n",
    "ax2.bar(poor['race'], poor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see what is the value of $p$ in our training data, because it is likely that such a pattern will reveal itself in the model. In other words, what is the maximum bias that is shown in the data? This is assuming there are no confounding variables between race groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proportion of black people who are rich. Dividing the \"length\" of the DFs of only >50k and the entire data, subsetting for black race\n",
    "blackrich = len(rich[rich['race'] == 0])/len(train[train['race'] == 0])\n",
    "#Same idea for other races\n",
    "nonblackrich = len(rich[rich['race'] == 1])/len(train[train['race'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More processing things, one-hot encoding categorical variables, making sure that the test and train have the same encodings, by using df.align on column case. Then, converting everything into numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "dumdf = pd.get_dummies(X, columns = [\"workclass\", \"education\", \"education.num\", \"marital.status\", \"occupation\", \"relationship\", \"sex\"], drop_first = True)\n",
    "testdf = pd.get_dummies(X_test, columns = [\"workclass\", \"education\", \"education.num\", \"marital.status\", \"occupation\", \"relationship\", \"sex\"], drop_first = True)\n",
    "dumdf_o = pd.get_dummies(X_o, columns = [\"workclass\", \"education\", \"education.num\", \"marital.status\", \"occupation\", \"relationship\", \"sex\"], drop_first =True)\n",
    "dumdf,testdf = dumdf.align(testdf, join='outer', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model\n",
    "\n",
    "Simple neural net using nonlinear mappings and cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20838 samples, validate on 5210 samples\n",
      "Epoch 1/5\n",
      "20838/20838 [==============================] - 2s 98us/sample - loss: 4.5292 - acc: 0.8064 - val_loss: 1.6252 - val_acc: 0.8134\n",
      "Epoch 2/5\n",
      "20838/20838 [==============================] - 1s 69us/sample - loss: 1.0834 - acc: 0.8277 - val_loss: 1.3371 - val_acc: 0.8395\n",
      "Epoch 3/5\n",
      "20838/20838 [==============================] - 1s 69us/sample - loss: 1.1030 - acc: 0.8307 - val_loss: 0.9601 - val_acc: 0.8503\n",
      "Epoch 4/5\n",
      "20838/20838 [==============================] - 2s 74us/sample - loss: 1.1062 - acc: 0.8321 - val_loss: 1.0272 - val_acc: 0.8536\n",
      "Epoch 5/5\n",
      "20838/20838 [==============================] - 1s 64us/sample - loss: 1.0834 - acc: 0.8276 - val_loss: 4.0567 - val_acc: 0.8144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "M1 = Input(shape=(nfeatures,),name='M1')\n",
    "M2 = Dense(400, activation='relu',name='M2')(M1)\n",
    "M3 = Dense(1, activation='sigmoid',name='M3')(M2)\n",
    "\n",
    "\n",
    "model = Model(inputs = [M1], outputs = [M3])\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "history = model.fit(dumdf,Y, batch_size = 32, epochs = 5, validation_split = 0.2, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin ML pipeline. Setting up a basic neural network structure (which can be tinkered with later). \n",
    "\n",
    "The idea is we are trying to predict M3 (average income), but at the same time we want to discriminate against predicting C2 (race). \n",
    "\n",
    "So the rough structure looks like: M1 -> M2 -> M3 (income) -> C2 -> C3 (race)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "M1 = Input(shape=(nfeatures,),name='M1')\n",
    "M2 = Dense(400, activation='relu',name='M2')(M1)\n",
    "M3 = Dense(1, activation='sigmoid',name='M3')(M2)\n",
    "C2 = Dense(40, activation='relu',name='C2')(M3)\n",
    "C3 = Dense(1, activation='sigmoid',name='C3')(C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model with adjusted loss function. Define some value $\\alpha$ that represents the \"discriminator\" network, that punishes the loss function when the loss for C3 is smaller. $\\alpha$ is an important hyperparamater to choose, though, since a large $\\alpha$ may drive the network away from any good convergence, while a small $\\alpha$ does little to nothing (obviously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20838 samples, validate on 5210 samples\n",
      "Epoch 1/5\n",
      "20838/20838 [==============================] - 3s 129us/sample - loss: 2.3179 - M3_loss: 2.3891 - C3_loss: 0.7397 - M3_acc: 0.8038 - C3_acc: 0.0956 - val_loss: 0.7214 - val_M3_loss: 0.8099 - val_C3_loss: 0.8863 - val_M3_acc: 0.8253 - val_C3_acc: 0.0973\n",
      "Epoch 2/5\n",
      "20838/20838 [==============================] - 2s 84us/sample - loss: 1.3324 - M3_loss: 1.4208 - C3_loss: 0.8987 - M3_acc: 0.8215 - C3_acc: 0.0956 - val_loss: 0.8695 - val_M3_loss: 0.9587 - val_C3_loss: 0.8996 - val_M3_acc: 0.8403 - val_C3_acc: 0.0973\n",
      "Epoch 3/5\n",
      "20838/20838 [==============================] - 2s 83us/sample - loss: 0.9849 - M3_loss: 1.0740 - C3_loss: 0.9024 - M3_acc: 0.8262 - C3_acc: 0.0956 - val_loss: 0.7159 - val_M3_loss: 0.8054 - val_C3_loss: 0.9014 - val_M3_acc: 0.8405 - val_C3_acc: 0.0973\n",
      "Epoch 4/5\n",
      "20838/20838 [==============================] - 2s 78us/sample - loss: 1.2478 - M3_loss: 1.3368 - C3_loss: 0.9038 - M3_acc: 0.8238 - C3_acc: 0.0956 - val_loss: 1.4428 - val_M3_loss: 1.5318 - val_C3_loss: 0.9020 - val_M3_acc: 0.8449 - val_C3_acc: 0.0973\n",
      "Epoch 5/5\n",
      "20838/20838 [==============================] - 2s 80us/sample - loss: 1.0634 - M3_loss: 1.1535 - C3_loss: 0.9041 - M3_acc: 0.8309 - C3_acc: 0.0956 - val_loss: 2.8202 - val_M3_loss: 2.9138 - val_C3_loss: 0.9024 - val_M3_acc: 0.8390 - val_C3_acc: 0.0973\n"
     ]
    }
   ],
   "source": [
    "merged = Model(inputs = [M1], outputs = [M3, C3])\n",
    "loss1 = 'binary_crossentropy'\n",
    "loss2 = 'mse'\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "alpha = 0.1\n",
    "merged.compile(optimizer = opt,loss=[loss1, loss2],loss_weights=[1, -1 * alpha], metrics=['accuracy'])\n",
    "history = merged.fit(dumdf, [Y,Y_race] ,batch_size=32, epochs=5, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Model\n",
    "Model with the oversampled training set, same neural network structure as the normal model though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23836 samples, validate on 5960 samples\n",
      "Epoch 1/5\n",
      "23836/23836 [==============================] - 2s 87us/sample - loss: 4.3093 - acc: 0.8113 - val_loss: 0.6493 - val_acc: 0.8765\n",
      "Epoch 2/5\n",
      "23836/23836 [==============================] - 2s 77us/sample - loss: 1.3255 - acc: 0.8261 - val_loss: 0.5917 - val_acc: 0.8790\n",
      "Epoch 3/5\n",
      "23836/23836 [==============================] - 2s 67us/sample - loss: 0.8247 - acc: 0.8334 - val_loss: 0.9977 - val_acc: 0.8809\n",
      "Epoch 4/5\n",
      "23836/23836 [==============================] - 2s 66us/sample - loss: 1.2990 - acc: 0.8343 - val_loss: 0.4866 - val_acc: 0.8896\n",
      "Epoch 5/5\n",
      "23836/23836 [==============================] - 2s 67us/sample - loss: 0.6913 - acc: 0.8386 - val_loss: 0.6391 - val_acc: 0.8829\n"
     ]
    }
   ],
   "source": [
    "M1 = Input(shape=(nfeatures,),name='M1')\n",
    "M2 = Dense(400, activation='relu',name='M2')(M1)\n",
    "M3 = Dense(1, activation='sigmoid',name='M3')(M2)\n",
    "\n",
    "\n",
    "Omodel = Model(inputs = [M1], outputs = [M3])\n",
    "Omodel.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "history = Omodel.fit(dumdf_o,Y_o, batch_size = 32, epochs = 5, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling + Combined Loss Function\n",
    "\n",
    "This one is supposed to combine our previous two insights. We expect this model to perform the \"best\" based on our ideas of debiasing. But anything is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23836 samples, validate on 5960 samples\n",
      "Epoch 1/5\n",
      "23836/23836 [==============================] - 3s 112us/sample - loss: 2.3466 - M3_loss: 2.4166 - C3_loss: 0.7041 - M3_acc: 0.8123 - C3_acc: 0.0980 - val_loss: 0.6492 - val_M3_loss: 0.6803 - val_C3_loss: 0.3312 - val_M3_acc: 0.8767 - val_C3_acc: 0.6628\n",
      "Epoch 2/5\n",
      "23836/23836 [==============================] - 2s 84us/sample - loss: 1.5793 - M3_loss: 1.6689 - C3_loss: 0.8958 - M3_acc: 0.8199 - C3_acc: 0.0964 - val_loss: 3.0030 - val_M3_loss: 3.0276 - val_C3_loss: 0.3372 - val_M3_acc: 0.8628 - val_C3_acc: 0.6628\n",
      "Epoch 3/5\n",
      "23836/23836 [==============================] - 2s 81us/sample - loss: 1.4850 - M3_loss: 1.5751 - C3_loss: 0.9015 - M3_acc: 0.8277 - C3_acc: 0.0964 - val_loss: 1.4299 - val_M3_loss: 1.4579 - val_C3_loss: 0.3360 - val_M3_acc: 0.8542 - val_C3_acc: 0.6628\n",
      "Epoch 4/5\n",
      "23836/23836 [==============================] - 2s 80us/sample - loss: 2.0075 - M3_loss: 2.0975 - C3_loss: 0.9027 - M3_acc: 0.8218 - C3_acc: 0.0964 - val_loss: 1.5640 - val_M3_loss: 1.5931 - val_C3_loss: 0.3382 - val_M3_acc: 0.8384 - val_C3_acc: 0.6628\n",
      "Epoch 5/5\n",
      "23836/23836 [==============================] - 2s 80us/sample - loss: 0.9192 - M3_loss: 1.0095 - C3_loss: 0.9031 - M3_acc: 0.8336 - C3_acc: 0.0964 - val_loss: 0.8918 - val_M3_loss: 0.9227 - val_C3_loss: 0.3368 - val_M3_acc: 0.8847 - val_C3_acc: 0.6628\n"
     ]
    }
   ],
   "source": [
    "M1 = Input(shape=(nfeatures,),name='M1')\n",
    "M2 = Dense(400, activation='relu',name='M2')(M1)\n",
    "M3 = Dense(1, activation='sigmoid',name='M3')(M2)\n",
    "C2 = Dense(40, activation='relu',name='C2')(M3)\n",
    "C3 = Dense(1, activation='sigmoid',name='C3')(C2)\n",
    "\n",
    "Omerged = Model(inputs = [M1], outputs = [M3, C3])\n",
    "loss1 = 'binary_crossentropy'\n",
    "loss2 = 'mse'\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "alpha = 0.1\n",
    "Omerged.compile(optimizer = opt,loss=[loss1, loss2],loss_weights=[1, -1 * alpha], metrics=['accuracy'])\n",
    "history = Omerged.fit(dumdf_o, [Y_o,Y_o_race] ,batch_size=32, epochs=5, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the models on test set\n",
    "scores_merged = merged.evaluate(testdf, [Y_test, Y_test_race], batch_size=16, verbose = 0)\n",
    "scores = model.evaluate(testdf, Y_test, batch_size = 16, verbose = 0)\n",
    "scores_o = Omodel.evaluate(testdf, Y_test, batch_size = 16, verbose = 0)\n",
    "scores_merged_o = Omerged.evaluate(testdf, [Y_test, Y_test_race], batch_size=16, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Loss Function Model: \n",
      "Loss: 2.4284602823518084\n",
      "Accuracy: 0.8298787\n",
      "Simple Model: \n",
      "Loss: 0.8953211289679933\n",
      "Accuracy: 0.83724856\n",
      "Oversampled Model: \n",
      "Loss: 0.6931385774958725\n",
      "Accuracy: 0.84077996\n",
      "Oversampling + Combined Loss Function Model: \n",
      "Loss: 0.9124806871726072\n",
      "Accuracy: 0.8389375\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined Loss Function Model: \\nLoss: \" + str(scores_merged[0]) + \"\\nAccuracy: \" + str(scores_merged[3]))\n",
    "\n",
    "print(\"Simple Model: \\nLoss: \" + str(scores[0]) + \"\\nAccuracy: \" + str(scores[1]))\n",
    "\n",
    "print(\"Oversampled Model: \\nLoss: \" + str(scores_o[0]) + \"\\nAccuracy: \" + str(scores_o[1]))\n",
    "\n",
    "print(\"Oversampling + Combined Loss Function Model: \\nLoss: \" + str(scores_merged_o[0]) + \"\\nAccuracy: \" + str(scores_merged_o[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vector = [scores[1], scores_merged[3], scores_o[1], scores_merged_o[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy in predicting income based on learning scheme')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debgdRZ3/8feHhLBkY4tIFglgIAQEhCuooOQnyOaCjgswoiQuGAUNjAjoOCMOIjiAoBMwAkJGB1nEwAAii/ILi6AkkUBIIBgTICEsCTsCQsh3/qi60Dk5955zt9xAfV7Pc590d1VXV1fX+XZ39ekTRQRmZlaWtXq7AmZmtvo5+JuZFcjB38ysQA7+ZmYFcvA3MyuQg7+ZWYEc/FcTSe+TNK+361GPpHGSbq3MPy9py06U8xlJ13dv7V4re46ksT1Rdk+TNFJSSOrby/UISW9/s2ynznZ7rP91Rm+1Q7PWmOAvaZqkpySt09t16QkRcUtEbNPb9WhGRAyIiAXt5akX0CLiwojYp4fqtF1ETOuJsu3NoSf735vRGhH8JY0E3gcE8NHVvO1evRrrbkrWiONq1l3cr7vfmtKYnwP+BEwBDqsmSBohaaqkpZKekDSpkvYlSfdKek7SXEk75+Ur3W5JmiLp+3l6rKTFko6T9ChwgaQNJV2dt/FUnh5eWX8jSRdIWpLTr8jL75H0kUq+tSUtk7RT7Q62brcy/4CkYyTdLekZSZdIWrde4+RhmT9K+q+c9z5Je1XSp0k6SdIfgReALSWNlnSDpCclzZP06Ur+jSVdKelZSXcAW9Vs77X2k7SepNMlPZi3fauk9YCbc/an8zDRe+oMH4WkCZL+mtvtLEnKaX1yucskLZR0ZHtDI7m99s7TJ0i6VNIv8rGfI6mlkrdun5G0lqTv5H15PK8/OKe13smMl7Qo13eCpHflY/R0te/ldT6f+99Tkq6TtHm9uld8PvehRyR9o1LOrpJuz9t4RNIkSf1ymiSdkev7TK7L9jltHUmnSXpI0mOSJudj01ruN3N5SyR9vr2KSRqa+8STkuZL+lIlrd32blBum3VU489dvX7dXp/qyf53nKSH8/7PU/785XK+LelvOW2mpBGVVfeut/28bpv9J9flq3nd5ySdKGmr3E+ezcejXyX/hyXNyn3oNkk7NDw4EdHrf8B84KvALsArwKZ5eR/gLuAMoD+wLrBHTvsU8DDwLkDA24HNc1oAb6+UPwX4fp4eCywHfgisA6wHbAx8AlgfGAj8Griisv5vgUuADYG1gT3z8mOBSyr5DgRmt7GPY4HFlfkHgDuAocBGwL3AhDbWHZfrfHTe/kHAM8BGOX0a8BCwHdAXGAwsAsbn+Z2BZcB2Of/FwKW5TbfP7XhrZXuvtR9wVi5/WD4e783tNjLn61tTz9pyrgY2AN4GLAX2y2kTgLnA8Nyuv68tr6YNHgD2ztMnAC8BB+Q6nQz8qYk+83lSX9sSGABMBX6Z01r3Z3JeZ5+8jSuAt+T9f7xy7D+Wy9o2t/F3gNvaqHtr2RflOr0jt0Xr/uwCvDuXMzL3haNy2r7AzNyGytvbLKedCVxJ6j8DgauAk3PafsBj+fj2B35Fzeeipo43AWfnfd8p12+vRu3dRlnV/tNeHRt97qaxcr9em/b71Dh6oP8B25A+T0Mrx3OrPP1NYHbOI2BHYOMmtt9u/8nrXgkMyvv/D+APpL47ONf9sJx3Z1Lf3C0fn8NIn5d12o27a0Dg34MU8DfJ8/cBR+fp9+QGq3dArgMmNup8eX4KKwf/l4F126nTTsBTeXozYAWwYZ18Q4HngEF5/jLg2DbKHMuqwf/Qyvx/ApPbWHccsARQZdkdwGcrH5L/qKQdBNxSU8bPgO/mzvEKMLqS9gPqBH/SneGLwI516jSS5oL/HpX5S4Hj8/SNwJcraXvXllezvQdYOfj/vpI2BnixiT7zB+CrNR/qV3g96AYwrJL+BHBQZf43vB6Ufwd8oZK2FunqdPN22qra5v8J/LyNfT0KuDxPfwC4n3RyWKuSR8DfyUGosu8L8/T5wCmVtK1pI/gDI4BXgYGVZScDUxq1d3ufv0Z1bO9zV69fN9GneqT/5X15POdZuyZtHnBgO+3Q1vbb7T953d0r6TOB4yrzpwNn5umfAifWqdeebR2jiFgjhn0OA66PiGV5/le8PvQzAngwIpbXWW8E8LdObnNpRLzUOiNpfUk/UxoOeJY0pLGBpD55O09GxFO1hUTEEuCPwCckbQDsD1zYgXo8Wpl+gXQ12paHIx/V7EHSyafVosr05sBu+RbwaUlPA58B3goMIQW7av4H29jmJqQrwc62M7S9j0Nr6lCd7ky56+Zb9vb6zFBW3tcHSW2xaWXZY5XpF+vMt9Z/c+DHlfZ9khTshrVT59o2Hwogaes85PFo7n8/ILU9EXEjMIl0B/aYpHMkDSIdx/WBmZU6XJuXt+5rM8e4Ne+TEfFcTf7qvrTV3u1pt44NPnet6vWLjnxuutz/ImI+6YR8AvC4pIsltX72GsWhtrbfTP/pSF/8Rs3nfQQrx4dV9Grwz2N/nwb2zB3/UdLQxo6SdiQdkLe10ckWUTNWXfECqdO1emtNetTMf4N0FbhbRAwC3t9axbydjXJwr+e/gUNJw1C3R8TDbeTrqmHV8ULSbeSSynx1nxYBN0XEBpW/ARHxFdJV8XJS56iWVc8y0u1+vXaubcOOeoR0y91qRFsZO6i9PrOE9EFp9TZSWzxWJ28z2/lyTRuvFxG3tbNObZu3Hr+fku54R+X+921S3wMgIn4SEbuQbv+3Jg01LCMFgO0q2x8cEa0B4ZE622vLElIfH1iTv6t9uVEd2/vctepqP2tLh/pfRPwqIvYg9Z8gDRtD+3GoPZ3pP+2VdVJNWetHxEXtrdTbV/4fI91ujiHd8u1EGgO7hfQQ+A7SQTpFUn9J60raPa97HnCMpF2UvL3ywGQW8M/5Ycx+wJ4N6jGQ1EmflrQRaXgEgIh4hHSLdnZ+QLW2pPdX1r2CNOY2EfhFJ9uhGW8Bvp63/ylSO13TRt6rga0lfTbnX1vpweW2EfEqaaz7hHzlNYaah+ytImIFafjgR0oPBPsoPdhdh3QSWUEag+yMS4GJkoblE+txnSynVnt95iLgaElbSBpAusK+pI27hEYmA9+StB2ApMH5uLTn33Kbb0d6HnNJXj4QeBZ4XtJo4CutK+TjtpuktUlDKC8Br+Zjcy5whqS35LzDJO2bV70UGCdpjKT1qfTpWhGxCLgNODm31w7AF+jYXWy9chvVsc3P3WrQdP+TtI2kD+R+/xKpzq/m5POAEyWNynFoB0kbN7H9zvSftpwLTMj9RLnff6jmZL6K3g7+hwEXRMRDEfFo6x/pNvczpCuAj5DG3B4CFpPGs4mIXwMnkYaJniMF4Y1yuRPzeq3DHVc0qMeZpAe/y0jfOrq2Jv2zpLHh+0hjf0e1JkTEi6Sx4C1IQbWn/BkYlet4EvDJiHiiXsZ8+74PcDDpqu5RXn/ADXAk6ZbxUdLzkAva2e4xpAda00m3pj8kjT2/kOvxx3yr+e4O7s+5wPXA3cCdpBPZcl7/UHVKPrnV7TOkE9kvScMLC0kf5K91cjuXk9ri4jxkcQ9p2K89N5Ee8v0BOC0iWl9IOgb4Z1I/PpfXTwqQHvidCzxFGop5Ajgtpx2Xy/tTrsPvSVfSRMTvSP36xpznxgZ1O4T0bGIJcDnw3Yi4ocE6zWizjjT+3PWkjvS/dYBTSPV8lHQh9u2c9iPSieR60gn856R9alcn+09bZc0AvkSKm0+R2ntco/W08jCydYakfwe2johDe6j8ccAX823nm5Kk/UkPvDdvmNmsm5XY/3r7yv8NL9+ufgE4p7fr8kai9P7AAZL6ShpGuuW/vLfrZWVw/2sy+EvaT+nFhvmSjq+TvqGky5VeQLlD+SWUZtZ9I1N6EWYR8LuIuLlRfluJgO+RblPvJH23/d97tUZWkuL7X8NhH6WvXd0PfJA0fjodOCQi5lbynAo8HxHfyw+szoqIvZpZ18zMVr9mrvx3BeZHxIKIeJn0duiBNXnGkB5iERH3ASMlbdrkumZmtpo186Nmw1j5BYjFpNeIq+4C/gm4VdKupO/CDm9yXQAkHQ4cDtC/f/9dRo8e3Uz9zcwMmDlz5rKIGNI4Z9JM8FedZbVjRaeQ3labRfpa4J2kr001s25aGHEO+aFpS0tLzJgxo4mqmZkZgKT23uJeRTPBfzErv/02nJXfLCUiniW9tEJ+C3Vh/lu/0bpmZrb6NTPmPx0Yld+K7Ed6cejKagZJG+j1nxf9InBzPiE0XNfMzFa/hlf+EbFc0pGkX9HsA5wfEXMkTcjpk0k/NfALSa+Sfmr0C+2t2zO7YmZmzVoj3/D1mL+ZWcdImhkRTf0nO+A3fM3MiuTgb2ZWIAd/M7MCOfibmRXIwd/MrEAO/mZmBXLwNzMrkIO/mVmBHPzNzArk4G9mViAHfzOzAjn4m5kVyMHfzKxADv5mZgVy8DczK5CDv5lZgRz8zcwK5OBvZlYgB38zswI5+JuZFcjB38ysQA7+ZmYFcvA3MyuQg7+ZWYEc/M3MCuTgb2ZWIAd/M7MCOfibmRXIwd/MrEAO/mZmBXLwNzMrkIO/mVmBHPzNzArk4G9mViAHfzOzAjUV/CXtJ2mepPmSjq+TPljSVZLukjRH0vhK2tF52T2SLpK0bnfugJmZdVzD4C+pD3AWsD8wBjhE0piabEcAcyNiR2AscLqkfpKGAV8HWiJie6APcHA31t/MzDqhmSv/XYH5EbEgIl4GLgYOrMkTwEBJAgYATwLLc1pfYD1JfYH1gSXdUnMzM+u0ZoL/MGBRZX5xXlY1CdiWFNhnAxMjYkVEPAycBjwEPAI8ExHX19uIpMMlzZA0Y+nSpR3cDTMz64hmgr/qLIua+X2BWcBQYCdgkqRBkjYk3SVskdP6Szq03kYi4pyIaImIliFDhjS9A2Zm1nHNBP/FwIjK/HBWHboZD0yNZD6wEBgN7A0sjIilEfEKMBV4b9erbWZmXdFM8J8OjJK0haR+pAe2V9bkeQjYC0DSpsA2wIK8/N2S1s/PA/YC7u2uypuZWef0bZQhIpZLOhK4jvRtnfMjYo6kCTl9MnAiMEXSbNIw0XERsQxYJuky4C+kB8B3Auf0zK6YmVmzFFE7fN/7WlpaYsaMGb1dDTOzNwxJMyOipdn8fsPXzKxADv5mZgVy8DczK5CDv5lZgRz8zcwK5OBvZlYgB38zswI5+JuZFcjB38ysQA7+ZmYFcvA3MyuQg7+ZWYEc/M3MCuTgb2ZWIAd/M7MCOfibmRXIwd/MrEAO/mZmBXLwNzMrkIO/mVmBHPzNzArk4G9mViAHfzOzAjn4m5kVyMHfzKxADv5mZgVy8DczK5CDv5lZgRz8zcwK5OBvZlYgB38zswI5+JuZFcjB38ysQA7+ZmYFair4S9pP0jxJ8yUdXyd9sKSrJN0laY6k8ZW0DSRdJuk+SfdKek937oCZmXVcw+AvqQ9wFrA/MAY4RNKYmmxHAHMjYkdgLHC6pH457cfAtRExGtgRuLeb6m5mZp3UzJX/rsD8iFgQES8DFwMH1uQJYKAkAQOAJ4HlkgYB7wd+DhARL0fE091WezMz65Rmgv8wYFFlfnFeVjUJ2BZYAswGJkbECmBLYClwgaQ7JZ0nqX+9jUg6XNIMSTOWLl3a0f0wM7MOaCb4q86yqJnfF5gFDAV2Aiblq/6+wM7ATyPincDfgVWeGQBExDkR0RIRLUOGDGm2/mZm1gnNBP/FwIjK/HDSFX7VeGBqJPOBhcDovO7iiPhzzncZ6WRgZma9qJngPx0YJWmL/BD3YODKmjwPAXsBSNoU2AZYEBGPAoskbZPz7QXM7Zaam5lZp/VtlCEilks6ErgO6AOcHxFzJE3I6ZOBE4EpkmaThomOi4hluYivARfmE8cC0l2CmZn1IkXUDt/3vpaWlpgxY0ZvV8PM7A1D0syIaGk2v9/wNTMrkIO/mVmBHPzNzArk4G9mViAHfzOzAjn4m5kVyMHfzKxADv5mZgVy8DczK5CDv5lZgRz8zcwK5OBvZlYgB38zswI5+JuZFcjB38ysQA7+ZmYFcvA3MyuQg7+ZWYEc/M3MCuTgb2ZWIAd/M7MCOfibmRXIwd/MrEAO/mZmBXLwNzMrkIO/mVmBHPzNzArk4G9mViAHfzOzAjn4m5kVyMHfzKxADv5mZgVy8DczK5CDv5lZgRz8zcwK1FTwl7SfpHmS5ks6vk76YElXSbpL0hxJ42vS+0i6U9LV3VVxMzPrvL6NMkjqA5wFfBBYDEyXdGVEzK1kOwKYGxEfkTQEmCfpwoh4OadPBO4FBnVv9c3WLCOP/21vV6FXPXDKh3q7CtakZq78dwXmR8SCHMwvBg6syRPAQEkCBgBPAssBJA0HPgSc1221NjOzLmkm+A8DFlXmF+dlVZOAbYElwGxgYkSsyGlnAscCK2iHpMMlzZA0Y+nSpc3U3czMOqmZ4K86y6Jmfl9gFjAU2AmYJGmQpA8Dj0fEzEYbiYhzIqIlIlqGDBnSRLXMzKyzGo75k670R1Tmh5Ou8KvGA6dERADzJS0ERgO7Ax+VdACwLjBI0v9ExKFdr7qZvdn4mcnqe2bSzJX/dGCUpC0k9QMOBq6syfMQsBeApE2BbYAFEfGtiBgeESPzejc68JuZ9b6GV/4RsVzSkcB1QB/g/IiYI2lCTp8MnAhMkTSbNEx0XEQs68F6m5lZFzQz7ENEXANcU7NscmV6CbBPgzKmAdM6XEMzM+t2TQX/NxKPGfp71mbWmH/ewcysQA7+ZmYFcvA3MyuQg7+ZWYEc/M3MCuTgb2ZWIAd/M7MCOfibmRXIwd/MrEAO/mZmBXLwNzMrkIO/mVmBHPzNzArk4G9mViAHfzOzAr3pfs/fusb/H4L/PwQrg6/8zcwK5OBvZlYgB38zswI5+JuZFcjB38ysQA7+ZmYFcvA3MyuQg7+ZWYEc/M3MCuTgb2ZWIAd/M7MCOfibmRXIwd/MrEAO/mZmBXLwNzMrkIO/mVmBHPzNzArUVPCXtJ+keZLmSzq+TvpgSVdJukvSHEnj8/IRkv6/pHvz8ondvQNmZtZxDYO/pD7AWcD+wBjgEEljarIdAcyNiB2BscDpkvoBy4FvRMS2wLuBI+qsa2Zmq1kzV/67AvMjYkFEvAxcDBxYkyeAgZIEDACeBJZHxCMR8ReAiHgOuBcY1m21NzOzTmkm+A8DFlXmF7NqAJ8EbAssAWYDEyNiRTWDpJHAO4E/19uIpMMlzZA0Y+nSpU1V3szMOqeZ4K86y6Jmfl9gFjAU2AmYJGnQawVIA4DfAEdFxLP1NhIR50RES0S0DBkypKnKm5lZ5zQT/BcDIyrzw0lX+FXjgamRzAcWAqMBJK1NCvwXRsTUrlfZzMy6qpngPx0YJWmL/BD3YODKmjwPAXsBSNoU2AZYkJ8B/By4NyJ+1H3VNjOzrmgY/CNiOXAkcB3pge2lETFH0gRJE3K2E4H3SpoN/AE4LiKWAbsDnwU+IGlW/jugR/bEzMya1reZTBFxDXBNzbLJleklwD511ruV+s8MzMysF/kNXzOzAjn4m5kVyMHfzKxADv5mZgVy8DczK5CDv5lZgRz8zcwK5OBvZlYgB38zswI5+JuZFcjB38ysQA7+ZmYFcvA3MyuQg7+ZWYEc/M3MCuTgb2ZWIAd/M7MCOfibmRXIwd/MrEAO/mZmBXLwNzMrkIO/mVmBHPzNzArk4G9mViAHfzOzAjn4m5kVyMHfzKxADv5mZgVy8DczK5CDv5lZgRz8zcwK5OBvZlYgB38zswI5+JuZFcjB38ysQE0Ff0n7SZonab6k4+ukD5Z0laS7JM2RNL7Zdc3MbPVrGPwl9QHOAvYHxgCHSBpTk+0IYG5E7AiMBU6X1K/Jdc3MbDVr5sp/V2B+RCyIiJeBi4EDa/IEMFCSgAHAk8DyJtc1M7PVrG8TeYYBiyrzi4HdavJMAq4ElgADgYMiYoWkZtYFQNLhwOF59nlJ85qo25poE2BZb21cP+ytLXcbt1/XuP265o3cfpt3JHMzwV91lkXN/L7ALOADwFbADZJuaXLdtDDiHOCcJuqzRpM0IyJaerseb1Ruv65x+3VNSe3XzLDPYmBEZX446Qq/ajwwNZL5wEJgdJPrmpnZatZM8J8OjJK0haR+wMGkIZ6qh4C9ACRtCmwDLGhyXTMzW80aDvtExHJJRwLXAX2A8yNijqQJOX0ycCIwRdJs0lDPcRGxDKDeuj2zK2uMN/zQVS9z+3WN269rimk/RdQdgjczszcxv+FrZlYgB38zswI5+NeQ9K/5JyruljRL0m6SzuuuN5MlPd8d5XQHSW+VdLGkv0maK+kaSVt3Q7lTJH2yzvIWST/pavm5rHGSJjW7fHWQNFzS/0r6a27TH+cvOryhSHpA0iZ5+rberk8j7bW7pPUlXShptqR7JN0qaUA3bHN/STMk3SvpPkmn5eUnSDqmq+WvDg7+FZLeA3wY2DkidgD2BhZFxBcjYm7v1q575bexLwemRcRWETEG+DawaU9tMyJmRMTXe6r83pTbcypwRUSMArYmve1+UhfLbeZdnB4TEe/tze030kS7TwQei4h3RMT2wBeAV9opb6SkaQ22uT3pxdZDI2JbYHvStxvfUBz8V7YZsCwi/gEQEcsiYomkaZJaIF25S/qhpJmSfi9p15y+QNJHc55x+Urk2vyjdt+ttzFJ35Q0Pd9lfG+17WXy/4BX8re1AIiIWRFxi5JT85XSbEkH5fqOlXSTpEsl3S/pFEmfkXRHzrdVpfy9Jd2S8324sv7VefoESedX2u61k4KkQ3OZsyT9TOk3opA0Ppd3E7B7R3ZW0r/k/blH0lF5WX9Jv1X6QcJ7Kvt5Sr4Turv1iq4JHwBeiogLclu+ChwNfD4f4+0qdZkmaZe8/fNz+p2SDszp4yT9WtJVwPWSNpN0c26PeyS9L+f7ab76nFPtP/nK/QeSbs/pO0u6Ll8VT6gci5slXZ73dbKkVeKB8p1qzj9N0mX5SvfCHHiRdEBedqukn7Qe49WkvXZfn/SZfrg1c0TMa/18d8GxwEkRcV8uc3lEnN3FMle/iPBf/iNdMcwC7gfOBvbMy6cBLXk6gP3z9OXA9cDawI7ArLx8HPAIsDGwHnBPZf3n87/7kL5WJtJJ+Grg/atxX78OnNFG2ieAG0hfz92U9B7HZqQf7Xs6T69D+lB9L68zETgzT08Brs37NYr0st+6ef2rc54TgNtyOZsAT+R23Ba4Clg75zsb+Fze5kPAEKAf8EdgUp26j6tdDuwCzAb652M8B3hn3s9zK/kGAxsB83j9m3AbdKU9gTuB71baaTPg/jz9A9LVI8AGud/1z/uwGNgop30D+Nc83QcYmKc3qiybBuyQ5x8AvpKnzwDuJv3syhDg8bx8LPASsGVe/wbgk5X1N6npr2OBZ0gvaq4F3A7skY/rImCLnO+i1mPcm/04t/sOwE7A47m+3wdGNShvJOluuL08fwF2bCPtBOCY1bX/XfnzlX9FRDxPChSHA0uBSySNq8n2MimwQQooN0XEK3l6ZCXfDRHxRES8SLot3aOmnH3y352kzjSaFCjXBHsAF0XEqxHxGHAT8K6cNj0iHol09fQ30skPVt3/SyNiRUT8lXRLPLrOdn4bEf+I9E7I46QTzV6kYzBd0qw8vyXpN6GmRcTSSD8SeEkH9+fyiPh7PsZTgfflOu+d7+TeFxHPAM+SguJ5kv4JeKHJbYj6P10iUmD+VJ7/NPDrPL0PcHzez2mkQPq2nHZDRDyZp6cD4yWdALwjIp5rLUvSX0h9aDvSL+e2an2Zcjbw54h4LiKWAi9J2iCn3RHpRxdfJQXt2j5a646IWBwRK0gXSSNJx3VBRCzMeS5qUEZ3a6/dIyJmkfrPqaQT+3RJ266SOd0BzQKuAVryXdYsVX6e/s2mV8cT10T5gzANmKb00tphNVleiXyKB1YArUNEK7Ty+Gxth6ydF3ByRPysWyrecXOAVR7KZvV+k6lV9ZZ5RWV+BSv3p0b7X1vWq3l9Af8dEd9aqULSx9oooxl19yci7pe0C3AAcLKk6yPiPyTtSjrpHAwcSRpaaGQO6U6iWudBpJ83mQ48IWkH4CDgy5V6fSIi5tWstxvw90o9b5b0fuBDwC8lnQrcAhwDvCsinpI0hXTyaFU9LrXHrPU4NXOMqto6Xr2pvXb/G7x2UTcVmCppBel431tdJyI+ntcdCUyJiLENtrkLcFd37EBv8ZV/haRtJFWvvncCHuxkcR+UtJGk9YCPkYYpqq4jjUsOyNseJuktndxWZ9wIrCPpS60LJL1L0p7AzcBBkvpIGgK8H7ijg+V/StJa+TnAlqShlGb8Afhka1vkNtwc+DMwVtLGktbm9SvpZtwMfEzpmx/9gY8Dt0gaCrwQEf8DnAbsnI/H4Ii4BjiK1Aearff6kj6X690HOJ0USF4g/Zz5sbns2Xmd64CvVcbO31mv4Lz/j0fEucDPgZ2BQaQTxDNKP6myfwfao9WuSj+9shbppHRrJ8q4D9gyB01yOatTu+0uaXdJG+a0fqS7o85+pludCnxb+ZtxuZ//SxfLXO185b+yAcB/5dvi5cB80hDQZZ0o61bgl8DbgV9FxIxqYkRcn28/b8+f/eeBQ0nDHz0uIkLSx4Ezlf6HtZdIY71HkYLle0hXNgEcGxGPSqo3dNOWeaThok2BCRHxUt7PRvWaK+k7pAeda5G+mXFERPwpD3vcTnqe8hfSWHU94/KdQqt3k55DtJ7AzouIOyXtC5yarwZfAb5CGhv/X0nrkq5qj25mZyvtebakfyNdWF1D+gYVpD70Y9JPobQ6ETgTuDufAB4gfdus1ljgm5JeIfWTz0XEQkl3kq5CF7DqxUUzbgdOAd5BOuaXd7SAiHhR0leBayUto+MXCV3SRLtvBfw0t+9awG+B33Rxm3crfWngovxQOXK5rb6T01vzD+/K9nqKf96hB+TnBC0RcWRv18WsHkljSQ8m651sOlrWgIh4PgfYs4C/RsQZXS3XepaHfcysq76UH5bOIX1jqreeY1kH+MrfzJ78FpgAAAAjSURBVKxAvvI3MyuQg7+ZWYEc/M3MCuTgb2ZWIAd/M7MC/R8kgJWYEvjKqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['Simple', 'Combined Loss', 'Oversampling', 'OS + CL'], accuracy_vector)\n",
    "plt.ylim(0.8, 0.9)\n",
    "plt.title(\"Accuracy in predicting income based on learning scheme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is interesting. The simple model does better than the combined one, but worse than the oversampling one in terms of pure accuracy. But that's not all that matters. We ought to see which does better in diagnosing bias. To do this, we can try computing the conditional probability $P(\\geq50K | black)$ on the predictions of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0832"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorical_tsfm(l):\n",
    "    # assert 0 < l[i] < 1\n",
    "    return [1 if x > 0.5 else 0 for x in l]\n",
    "\n",
    "# gets all indexes of a list that hit the match\n",
    "def get_indexes(l, match):\n",
    "    return [i for i,x in enumerate(l) if x == match]\n",
    "\n",
    "black_index = get_indexes(Y_test_race, 0)\n",
    "num_black = len(Y_test_race[Y_test_race ==0])\n",
    "\n",
    "#Simple Model\n",
    "result = model.predict(testdf)\n",
    "result = categorical_tsfm(result)\n",
    "result_index = get_indexes(result, 1)\n",
    "shared = list(set(black_index) & set(result_index))\n",
    "P_simple = len(shared)/num_black\n",
    "\n",
    "#Combined Model\n",
    "result = list(merged.predict(testdf)[0])\n",
    "result = categorical_tsfm(result)\n",
    "result_index = get_indexes(result, 1)\n",
    "shared= list(set(black_index) & set(result_index))\n",
    "P_merged = len(shared)/num_black\n",
    "\n",
    "#Oversampled Model\n",
    "result = Omodel.predict(testdf)\n",
    "result = categorical_tsfm(result)\n",
    "result_index = get_indexes(result, 1)\n",
    "shared = list(set(black_index) & set(result_index))\n",
    "P_over = len(shared)/num_black\n",
    "\n",
    "#Oversample + combined Model\n",
    "result = list(Omerged.predict(testdf)[0])\n",
    "result = categorical_tsfm(result)\n",
    "result_index = get_indexes(result, 1)\n",
    "shared = list(set(black_index) & set(result_index))\n",
    "P_over_merged = len(shared)/num_black\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['Simple', 'Combined Loss', 'Oversampling', 'OS + CL'], [P_simple, P_merged, P_over, P_over_merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
